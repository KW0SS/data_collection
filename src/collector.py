"""ë°ì´í„° ìˆ˜ì§‘ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°.

ê¸°ì—… ëª©ë¡(CSV or ì§ì ‘ ì…ë ¥) + ì—°ë„ ë²”ìœ„ â†’ ë¶„ê¸°ë³„ ì¬ë¬´ë¹„ìœ¨ CSV ì¶œë ¥.
ì„ íƒì ìœ¼ë¡œ ì›ë³¸ ì¬ë¬´ì œí‘œ JSONì„ ë¡œì»¬(data/raw/) ë˜ëŠ” S3ì— ì €ì¥.
ì¤‘ë³µ ë°ì´í„°ëŠ” ìë™ìœ¼ë¡œ ê±´ë„ˆë›°ê³ , ëˆ„ë½ ë¶„ê¸°ë§Œ ì¶”ê°€ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import csv
import json
import sys
import time
from collections import defaultdict
from pathlib import Path
from typing import Any

from .dart_api import (
    DartApiError,
    REPORT_CODES,
    fetch_financial_statements,
    get_api_key,
    resolve_corp_code,
)
from .account_mapper import extract_standard_items
from .ratio_calculator import RATIO_NAMES, compute_all_ratios
from .s3_uploader import upload_batch_to_s3

# â”€â”€ ê¸°ë³¸ ê²½ë¡œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_DIR = Path(__file__).resolve().parent.parent / "data"
OUTPUT_DIR = DATA_DIR / "output"
INPUT_DIR = DATA_DIR / "input"
RAW_DIR = DATA_DIR / "raw"


def _ensure_dirs(save_raw: bool = False) -> None:
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    INPUT_DIR.mkdir(parents=True, exist_ok=True)
    if save_raw:
        RAW_DIR.mkdir(parents=True, exist_ok=True)


def _save_raw_json(
    raw_items: list[dict[str, Any]],
    stock_code: str,
    year: str,
    quarter: str,
    fs_div: str,
) -> None:
    """ì›ë³¸ ì¬ë¬´ì œí‘œ JSONì„ data/raw/ í´ë”ì— ì €ì¥."""
    filename = f"{stock_code}_{year}_{quarter}_{fs_div}.json"
    path = RAW_DIR / filename
    path.write_text(
        json.dumps(raw_items, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )


# â”€â”€ ì¤‘ë³µ ì²´í¬: ê¸°ì¡´ CSVì—ì„œ ìˆ˜ì§‘ ì™„ë£Œëœ ë¶„ê¸° ëª©ë¡ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€
FIELDNAMES = ["stock_code", "corp_name", "year", "quarter", "label"] + RATIO_NAMES


def _load_existing_quarters(
    save_dir: Path,
    stock_code: str,
    year: str,
) -> set[str]:
    """ê¸°ì¡´ CSVì—ì„œ ì´ë¯¸ ìˆ˜ì§‘ëœ ë¶„ê¸° ëª©ë¡ì„ ë°˜í™˜.

    Returns:
        {"Q1", "H1"} í˜•íƒœì˜ set. íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ set.
    """
    filepath = save_dir / f"{stock_code}_{year}.csv"
    if not filepath.exists():
        return set()
    quarters: set[str] = set()
    with open(filepath, newline="", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for row in reader:
            q = (row.get("quarter") or "").strip()
            if q:
                quarters.add(q)
    return quarters


def _load_existing_rows(
    save_dir: Path,
    stock_code: str,
    year: str,
) -> list[dict[str, Any]]:
    """ê¸°ì¡´ CSV íŒŒì¼ì˜ ëª¨ë“  í–‰ì„ ì½ì–´ì„œ ë°˜í™˜.

    Returns:
        í–‰ ë¦¬ìŠ¤íŠ¸. íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸.
    """
    filepath = save_dir / f"{stock_code}_{year}.csv"
    if not filepath.exists():
        return []
    rows: list[dict[str, Any]] = []
    with open(filepath, newline="", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for row in reader:
            rows.append(dict(row))
    return rows


# â”€â”€ CSV ì…ë ¥ íŒŒì‹± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_company_list(csv_path: Path) -> list[dict[str, str]]:
    """
    ê¸°ì—… ëª©ë¡ CSV ì½ê¸°.

    CSV ì»¬ëŸ¼ (í—¤ë” í•„ìˆ˜):
      stock_code   â€“ ì¢…ëª©ì½”ë“œ (6ìë¦¬, ì˜ˆ: 005930)
      corp_name    â€“ ê¸°ì—…ëª… (ì°¸ê³ ìš©)
      label        â€“ 0=ì •ìƒ, 1=ìƒí (ì°¸ê³ ìš©, ìˆ˜ì§‘ì—ëŠ” ë¯¸ì‚¬ìš©)

    Optional:
      corp_code    â€“ DART ê³ ìœ ì½”ë“œ (ìˆìœ¼ë©´ API ë³€í™˜ ìƒëµ)
    """
    if not csv_path.exists():
        raise FileNotFoundError(f"ê¸°ì—… ëª©ë¡ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {csv_path}")

    rows: list[dict[str, str]] = []
    with open(csv_path, newline="", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        for row in reader:
            rows.append({k.strip(): (v or "").strip() for k, v in row.items()})
    return rows


# â”€â”€ ë‹¨ì¼ ê¸°ì—…Â·ë‹¨ì¼ ë³´ê³ ì„œ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def collect_single(
    api_key: str,
    corp_code: str,
    stock_code: str,
    corp_name: str,
    year: str,
    quarter: str,
    fs_div: str = "CFS",
    save_raw: bool = False,
) -> tuple[dict[str, Any], list[dict[str, Any]]]:
    """
    í•œ ê¸°ì—…ì˜ í•œ ë¶„ê¸° ì¬ë¬´ë¹„ìœ¨ì„ ìˆ˜ì§‘.

    Returns:
        (ratio_row, raw_items) íŠœí”Œ.
        ratio_row: {"stock_code": ..., "corp_name": ..., "ë¹„ìœ¨1": val, ...}
        raw_items: DART ì›ë³¸ ë°ì´í„° (ë°ì´í„° ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    """
    reprt_code = REPORT_CODES[quarter]
    try:
        raw_items = fetch_financial_statements(
            api_key, corp_code, year, reprt_code, fs_div
        )
    except DartApiError as e:
        print(f"  âš  API ì˜¤ë¥˜ ({corp_name} {year}-{quarter}): {e}", file=sys.stderr)
        raw_items = []

    if raw_items and save_raw:
        _save_raw_json(raw_items, stock_code, year, quarter, fs_div)

    if not raw_items:
        ratios = {name: None for name in RATIO_NAMES}
    else:
        std_items = extract_standard_items(raw_items)
        ratios = compute_all_ratios(std_items)

    row: dict[str, Any] = {
        "stock_code": stock_code,
        "corp_name": corp_name,
        "year": year,
        "quarter": quarter,
    }
    row.update(ratios)
    return row, raw_items


# â”€â”€ ë°°ì¹˜ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def collect_batch(
    stock_codes: list[str] | None = None,
    corp_codes: list[str] | None = None,
    years: list[str] | None = None,
    quarters: list[str] | None = None,
    companies_csv: Path | None = None,
    fs_div: str = "CFS",
    output_dir: Path | None = None,
    api_key: str | None = None,
    delay: float = 0.5,
    save_raw: bool = False,
    upload_s3: bool = False,
    s3_bucket: str | None = None,
    s3_region: str | None = None,
    force: bool = False,
) -> list[Path]:
    """
    ì—¬ëŸ¬ ê¸°ì—… Ã— ì—°ë„ Ã— ë¶„ê¸°ì˜ ì¬ë¬´ë¹„ìœ¨ì„ ìˆ˜ì§‘í•˜ì—¬ CSV ì €ì¥.

    íŒŒì¼ëª… ê·œì¹™: {ì¢…ëª©ì½”ë“œ}_{ì—°ë„}.csv  (ì˜ˆ: 019440_2023.csv)
    ê° ê¸°ì—… Ã— ì—°ë„ë³„ë¡œ ë³„ë„ì˜ CSV íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
    ì´ë¯¸ ìˆ˜ì§‘ëœ (ì¢…ëª©ì½”ë“œ, ì—°ë„, ë¶„ê¸°) ì¡°í•©ì€ ê±´ë„ˆë›°ê³  ëˆ„ë½ ë¶„ê¸°ë§Œ ì¶”ê°€í•©ë‹ˆë‹¤.

    ì‚¬ìš© ë°©ì‹ ë‘ ê°€ì§€:
    1) companies_csv ì§€ì • â†’ CSVì—ì„œ ê¸°ì—… ëª©ë¡ ë¡œë“œ
    2) stock_codes/corp_codes ì§ì ‘ ì „ë‹¬

    Args:
        stock_codes: ì¢…ëª©ì½”ë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["005930", "035720"])
        corp_codes: DART ê³ ìœ ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        years: ìˆ˜ì§‘ ì—°ë„ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["2022", "2023"])
        quarters: ë¶„ê¸° ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["Q1", "H1", "Q3", "ANNUAL"])
        companies_csv: ê¸°ì—… ëª©ë¡ CSV íŒŒì¼ ê²½ë¡œ
        fs_div: "CFS" (ì—°ê²°) ë˜ëŠ” "OFS" (ë³„ë„)
        output_dir: ê²°ê³¼ CSV ì €ì¥ ë””ë ‰í„°ë¦¬ (ê¸°ë³¸: data/output/)
        api_key: DART API í‚¤
        delay: API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
        save_raw: ì›ë³¸ ì¬ë¬´ì œí‘œ JSONì„ data/raw/ì— ì €ì¥í• ì§€ ì—¬ë¶€
        upload_s3: ì›ë³¸ ì¬ë¬´ì œí‘œë¥¼ S3ì— ì—…ë¡œë“œí• ì§€ ì—¬ë¶€
        s3_bucket: S3 ë²„í‚· ì´ë¦„ (ì—†ìœ¼ë©´ .envì—ì„œ ì½ê¸°)
        s3_region: AWS ë¦¬ì „ (ì—†ìœ¼ë©´ .envì—ì„œ ì½ê¸°)
        force: Trueì´ë©´ ì¤‘ë³µ ì²´í¬ë¥¼ ë¬´ì‹œí•˜ê³  ì „ì²´ ì¬ìˆ˜ì§‘

    Returns:
        ì €ì¥ëœ CSV íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    _ensure_dirs(save_raw=save_raw)
    key = get_api_key(api_key)

    if quarters is None:
        quarters = list(REPORT_CODES.keys())
    if years is None:
        years = ["2023"]

    # ê¸°ì—… ëª©ë¡ êµ¬ì„±
    companies: list[dict[str, str]] = []

    if companies_csv:
        companies = load_company_list(companies_csv)
    elif stock_codes:
        for sc in stock_codes:
            companies.append({"stock_code": sc, "corp_name": "", "corp_code": ""})
    elif corp_codes:
        for cc in corp_codes:
            companies.append({"stock_code": "", "corp_name": "", "corp_code": cc})
    else:
        raise ValueError("ê¸°ì—… ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤. stock_codes, corp_codes, ë˜ëŠ” companies_csvë¥¼ ì§€ì •í•˜ì„¸ìš”.")

    # corp_code í™•ë³´
    for comp in companies:
        if not comp.get("corp_code"):
            try:
                comp["corp_code"] = resolve_corp_code(
                    key,
                    stock_code=comp.get("stock_code"),
                    corp_name=comp.get("corp_name") or None,
                )
            except DartApiError as e:
                print(f"  âš  ê¸°ì—…ì½”ë“œ í™•ì¸ ì‹¤íŒ¨ ({comp}): {e}", file=sys.stderr)
                comp["corp_code"] = ""

    # â”€â”€ ì €ì¥ ë””ë ‰í„°ë¦¬ ê²°ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    save_dir = output_dir if output_dir else OUTPUT_DIR
    save_dir.mkdir(parents=True, exist_ok=True)

    # â”€â”€ ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•œ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # existing_quarters[(stock_code, year)] = {"Q1", "H1", ...}
    existing_quarters: dict[tuple[str, str], set[str]] = {}
    if not force:
        for comp in companies:
            sc = comp.get("stock_code", "")
            if not sc:
                continue
            for yr in years:
                eq = _load_existing_quarters(save_dir, sc, yr)
                if eq:
                    existing_quarters[(sc, yr)] = eq

    # â”€â”€ ê²°ê³¼ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    new_rows: list[dict[str, Any]] = []
    s3_upload_queue: list[dict[str, Any]] = []
    total = len(companies) * len(years) * len(quarters)
    done = 0
    skipped = 0

    for comp in companies:
        cc = comp.get("corp_code", "")
        sc = comp.get("stock_code", "")
        cn = comp.get("corp_name", "")
        gics = comp.get("gics_sector", "Unknown")
        if not cc:
            print(f"  â­ ê±´ë„ˆëœ€ (corp_code ì—†ìŒ): {sc} {cn}", file=sys.stderr)
            done += len(years) * len(quarters)
            continue

        for yr in years:
            for q in quarters:
                done += 1

                # â”€â”€ ì¤‘ë³µ ì²´í¬ â”€â”€
                if not force and q in existing_quarters.get((sc, yr), set()):
                    print(
                        f"  [{done}/{total}] {cn or sc} {yr}-{q} ... "
                        f"â­ ì´ë¯¸ ìˆ˜ì§‘ë¨ (SKIP)",
                        file=sys.stderr,
                    )
                    skipped += 1
                    continue

                print(f"  [{done}/{total}] {cn or sc} {yr}-{q} ... ìˆ˜ì§‘ ì¤‘", file=sys.stderr)

                # CFS ì‹œë„ â†’ ì‹¤íŒ¨í•˜ë©´ OFS í´ë°±
                row, raw_items = collect_single(key, cc, sc, cn, yr, q, fs_div, save_raw=save_raw)
                if fs_div == "CFS" and all(row.get(n) is None for n in RATIO_NAMES):
                    row, raw_items = collect_single(key, cc, sc, cn, yr, q, "OFS", save_raw=save_raw)

                row["label"] = comp.get("label", "")
                new_rows.append(row)

                # S3 ì—…ë¡œë“œ ëŒ€ê¸°ì—´ì— ì¶”ê°€
                if upload_s3 and raw_items:
                    s3_upload_queue.append({
                        "raw_items": raw_items,
                        "stock_code": sc,
                        "year": yr,
                        "quarter": q,
                        "gics_sector": gics,
                    })

                if delay > 0:
                    time.sleep(delay)

    # â”€â”€ CSV ì €ì¥: ê¸°ì¡´ ë°ì´í„° + ì‹ ê·œ ë°ì´í„° ë³‘í•© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì‹ ê·œ ë°ì´í„°ë¥¼ (stock_code, year) ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í•‘
    new_groups: dict[tuple[str, str], list[dict[str, Any]]] = defaultdict(list)
    for row in new_rows:
        grp_key = (row["stock_code"], row["year"])
        new_groups[grp_key].append(row)

    saved_files: list[Path] = []
    quarter_order = list(REPORT_CODES.keys())  # Q1, H1, Q3, ANNUAL

    # ì‹ ê·œ ë°ì´í„°ê°€ ìˆëŠ” íŒŒì¼ë§Œ ì €ì¥
    for (sc, yr), rows in new_groups.items():
        # ê¸°ì¡´ CSV í–‰ ë¡œë“œ (forceë©´ ë¬´ì‹œ)
        if force:
            merged = rows
        else:
            existing_rows = _load_existing_rows(save_dir, sc, yr)
            # ê¸°ì¡´ ë¶„ê¸° + ì‹ ê·œ ë¶„ê¸° ë³‘í•©
            existing_q_set = {r.get("quarter") for r in existing_rows}
            merged = list(existing_rows)
            for r in rows:
                if r["quarter"] not in existing_q_set:
                    merged.append(r)

        # ë¶„ê¸° ìˆœì„œëŒ€ë¡œ ì •ë ¬
        merged.sort(key=lambda r: quarter_order.index(r.get("quarter", "")) if r.get("quarter", "") in quarter_order else 99)

        filename = f"{sc}_{yr}.csv"
        filepath = save_dir / filename
        with open(filepath, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=FIELDNAMES, extrasaction="ignore")
            writer.writeheader()
            for row in merged:
                writer.writerow(row)
        saved_files.append(filepath)
        print(f"  ğŸ“„ {filepath}  ({len(merged)}í–‰)", file=sys.stderr)

    collected = len(new_rows)
    print(
        f"\nâœ… ì™„ë£Œ: ì‹ ê·œ {collected}ê±´ ìˆ˜ì§‘, {skipped}ê±´ ìŠ¤í‚µ"
        f"  ({len(saved_files)}ê°œ íŒŒì¼ ì €ì¥)",
        file=sys.stderr,
    )

    # â”€â”€ S3 ì—…ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if upload_s3 and s3_upload_queue:
        print(f"\nâ˜ï¸  S3 ì—…ë¡œë“œ ì‹œì‘ ({len(s3_upload_queue)}ê°œ íŒŒì¼)...", file=sys.stderr)
        upload_batch_to_s3(
            s3_upload_queue,
            bucket=s3_bucket,
            region=s3_region,
            force=force,
        )

    return saved_files
