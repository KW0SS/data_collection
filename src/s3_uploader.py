"""S3 ì—…ë¡œë“œ ëª¨ë“ˆ â€“ ì›ë³¸ ì¬ë¬´ì œí‘œ JSONì„ GICS ì„¹í„°ë³„ë¡œ S3ì— ì €ì¥.

S3 ë””ë ‰í„°ë¦¬ êµ¬ì¡°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
s3://{bucket}/
  â””â”€â”€ {gics_sector}/
      â”œâ”€â”€ 019440_2023_Q1.json
      â”œâ”€â”€ 019440_2023_H1.json
      â”œâ”€â”€ 019440_2023_Q3.json
      â””â”€â”€ 019440_2023_ANNUAL.json

í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜ (.env)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  S3_ACCESS_KEY    â€“ AWS Access Key ID
  S3_PRIVATE_KEY   â€“ AWS Secret Access Key
  S3_BUCKET_NAME   â€“ S3 ë²„í‚· ì´ë¦„
  S3_REGION        â€“ (ì„ íƒ) AWS ë¦¬ì „ (ê¸°ë³¸: ap-northeast-2)
"""

from __future__ import annotations

import json
import os
import sys
from pathlib import Path
from typing import Any


def _load_env() -> dict[str, str]:
    """í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ì½ê¸°."""
    env: dict[str, str] = {}
    env_path = Path(__file__).resolve().parent.parent / ".env"
    if not env_path.exists():
        return env
    for line in env_path.read_text().splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        if "=" not in line:
            continue
        key, value = line.split("=", 1)
        env[key.strip()] = value.strip().strip('"').strip("'")
    return env


def _get_s3_config(
    bucket: str | None = None,
    region: str | None = None,
) -> dict[str, str]:
    """S3 ì ‘ì† ì •ë³´ë¥¼ í™˜ê²½ë³€ìˆ˜ + .envì—ì„œ ê°€ì ¸ì˜´."""
    env = _load_env()

    access_key = os.getenv("S3_ACCESS_KEY") or env.get("S3_ACCESS_KEY")
    secret_key = os.getenv("S3_PRIVATE_KEY") or env.get("S3_PRIVATE_KEY")
    bucket_name = bucket or os.getenv("S3_BUCKET_NAME") or env.get("S3_BUCKET_NAME")
    region_name = region or os.getenv("S3_REGION") or env.get("S3_REGION", "ap-northeast-2")

    if not access_key or not secret_key:
        raise RuntimeError(
            "S3 ì¸ì¦ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .envì— S3_ACCESS_KEY, S3_PRIVATE_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”."
        )
    if not bucket_name:
        raise RuntimeError(
            "S3 ë²„í‚· ì´ë¦„ì´ ì—†ìŠµë‹ˆë‹¤. --s3-bucket ì˜µì…˜ì´ë‚˜ .envì— S3_BUCKET_NAMEì„ ì„¤ì •í•˜ì„¸ìš”."
        )

    return {
        "access_key": access_key,
        "secret_key": secret_key,
        "bucket": bucket_name,
        "region": region_name,
    }


def _get_s3_client(config: dict[str, str]):
    """boto3 S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±."""
    try:
        import boto3
    except ImportError:
        raise RuntimeError(
            "boto3ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install boto3 ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
        )

    return boto3.client(
        "s3",
        aws_access_key_id=config["access_key"],
        aws_secret_access_key=config["secret_key"],
        region_name=config["region"],
    )


def _try_create_bucket(client, bucket: str, region: str) -> None:
    """ë²„í‚·ì´ ì—†ì„ ë•Œ ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤.

    IAM ì‚¬ìš©ìì— CreateBucket ê¶Œí•œì´ ì—†ìœ¼ë©´ ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ë„˜ì–´ê°‘ë‹ˆë‹¤.
    (PutObject ê¶Œí•œë§Œ ìˆì–´ë„ ê¸°ì¡´ ë²„í‚·ì— ì—…ë¡œë“œëŠ” ê°€ëŠ¥)
    """
    try:
        print(f"  ğŸª£ S3 ë²„í‚· '{bucket}' ìƒì„± ì‹œë„ ì¤‘...", file=sys.stderr)
        if region == "us-east-1":
            client.create_bucket(Bucket=bucket)
        else:
            client.create_bucket(
                Bucket=bucket,
                CreateBucketConfiguration={"LocationConstraint": region},
            )
        print(f"  âœ… S3 ë²„í‚· '{bucket}' ìƒì„± ì™„ë£Œ", file=sys.stderr)
    except client.exceptions.ClientError as e:
        error_code = e.response.get("Error", {}).get("Code", "")
        if error_code in ("BucketAlreadyOwnedByYou", "BucketAlreadyExists"):
            print(f"  âœ… S3 ë²„í‚· '{bucket}' ì´ë¯¸ ì¡´ì¬", file=sys.stderr)
        elif error_code == "AccessDenied":
            print(
                f"  âš ï¸  ë²„í‚· ìƒì„± ê¶Œí•œ ì—†ìŒ (ê¸°ì¡´ ë²„í‚·ì— ì§ì ‘ ì—…ë¡œë“œ ì‹œë„)",
                file=sys.stderr,
            )
        else:
            raise


def upload_raw_to_s3(
    raw_items: list[dict[str, Any]],
    stock_code: str,
    year: str,
    quarter: str,
    gics_sector: str,
    bucket: str | None = None,
    region: str | None = None,
) -> str:
    """
    ì›ë³¸ ì¬ë¬´ì œí‘œ JSON 1ê±´ì„ S3ì— ì—…ë¡œë“œ.

    S3 Key: {gics_sector}/{stock_code}_{year}_{quarter}.json

    Args:
        raw_items: DARTì—ì„œ ë°›ì€ ì›ì‹œ ì¬ë¬´ì œí‘œ ë°ì´í„°
        stock_code: ì¢…ëª©ì½”ë“œ
        year: ì—°ë„
        quarter: ë¶„ê¸° (Q1, H1, Q3, ANNUAL)
        gics_sector: GICS ì„¹í„°ëª… (ì˜ˆ: "Energy", "Industrials")
        bucket: S3 ë²„í‚· ì´ë¦„ (ì—†ìœ¼ë©´ .envì—ì„œ ì½ê¸°)
        region: AWS ë¦¬ì „ (ì—†ìœ¼ë©´ .envì—ì„œ ì½ê¸°)

    Returns:
        ì—…ë¡œë“œëœ S3 key
    """
    config = _get_s3_config(bucket, region)
    client = _get_s3_client(config)

    # S3 key ìƒì„±: {gics_sector}/{stock_code}_{year}_{quarter}.json
    s3_key = f"{gics_sector}/{stock_code}_{year}_{quarter}.json"
    body = json.dumps(raw_items, ensure_ascii=False, indent=2).encode("utf-8")

    # ì—…ë¡œë“œ ì‹œë„ â†’ NoSuchBucketì´ë©´ ë²„í‚· ìƒì„± í›„ ì¬ì‹œë„
    try:
        client.put_object(
            Bucket=config["bucket"], Key=s3_key, Body=body,
            ContentType="application/json; charset=utf-8",
        )
    except client.exceptions.NoSuchBucket:
        _try_create_bucket(client, config["bucket"], config["region"])
        client.put_object(
            Bucket=config["bucket"], Key=s3_key, Body=body,
            ContentType="application/json; charset=utf-8",
        )

    return f"s3://{config['bucket']}/{s3_key}"


def upload_batch_to_s3(
    raw_data_list: list[dict[str, Any]],
    bucket: str | None = None,
    region: str | None = None,
) -> list[str]:
    """
    ì—¬ëŸ¬ ê±´ì˜ ì›ë³¸ ì¬ë¬´ì œí‘œë¥¼ S3ì— ë°°ì¹˜ ì—…ë¡œë“œ.

    Args:
        raw_data_list: [
            {
                "raw_items": [...],
                "stock_code": "019440",
                "year": "2023",
                "quarter": "Q1",
                "gics_sector": "Materials",
            },
            ...
        ]

    Returns:
        ì—…ë¡œë“œëœ S3 key ë¦¬ìŠ¤íŠ¸
    """
    if not raw_data_list:
        return []

    config = _get_s3_config(bucket, region)
    client = _get_s3_client(config)
    bucket_name = config["bucket"]
    bucket_checked = False  # NoSuchBucket ë°œìƒ ì‹œ í•œ ë²ˆë§Œ ìƒì„± ì‹œë„

    uploaded: list[str] = []

    for entry in raw_data_list:
        s3_key = (
            f"{entry['gics_sector']}/"
            f"{entry['stock_code']}_{entry['year']}_{entry['quarter']}.json"
        )
        body = json.dumps(
            entry["raw_items"], ensure_ascii=False, indent=2
        ).encode("utf-8")

        try:
            client.put_object(
                Bucket=bucket_name, Key=s3_key, Body=body,
                ContentType="application/json; charset=utf-8",
            )
        except client.exceptions.NoSuchBucket:
            if not bucket_checked:
                _try_create_bucket(client, bucket_name, config["region"])
                bucket_checked = True
                # ì¬ì‹œë„
                client.put_object(
                    Bucket=bucket_name, Key=s3_key, Body=body,
                    ContentType="application/json; charset=utf-8",
                )
            else:
                raise

        s3_uri = f"s3://{bucket_name}/{s3_key}"
        uploaded.append(s3_uri)
        print(f"  â˜ï¸  {s3_uri}", file=sys.stderr)

    print(
        f"\nâœ… S3 ì—…ë¡œë“œ ì™„ë£Œ: {len(uploaded)}ê°œ íŒŒì¼ â†’ s3://{config['bucket']}/",
        file=sys.stderr,
    )
    return uploaded
